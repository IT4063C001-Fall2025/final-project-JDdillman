{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# {The Rising Impact of Data Breaches in the U.S.}üìù\n",
    "\n",
    "![Banner](./assets/banner.jpeg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic\n",
    "*What problem are you (or your stakeholder) trying to address?*\n",
    "üìù <!-- Answer Below -->\n",
    "I want to talk about cybersecurity and data privacy, specifically analyzing patterns in data \n",
    "breaches in the United States. Every year, millions of people are affected by compromised personal \n",
    "data, which can result in identity theft, financial loss, and a decline in faith in businesses and \n",
    "technology. The rise of cloud platforms, artificial intelligence, and digitalservices has led to a \n",
    "rise in the collection of sensitive data, but laws and safeguards are frequently lagging behind. \n",
    "This makes the topic important today. Analyzing breach trends can help us identify weak points and \n",
    "improve data security for both individuals and corporations."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Question\n",
    "*What specific question are you seeking to answer with this project?*\n",
    "*This is not the same as the questions you ask to limit the scope of the project.*\n",
    "üìù <!-- Answer Below -->\n",
    "1. How have data breaches in the US changed over time in terms of both quantity and severity?\n",
    "2. Which sectors are most commonly the focus of data breaches caused by cyberattacks?\n",
    "3. What types of data (financial, healthcare, personal identifiers, etc.) are most often compromised, and what patterns exist?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What would an answer look like?\n",
    "*What is your hypothesized answer to your question?*\n",
    "üìù <!-- Answer Below -->\n",
    "A line chart showing the number of breaches per year.\n",
    "A bar chart comparing breaches across industries.\n",
    "A stacked bar or pie chart showing the breakdown of data types exposed."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Sources\n",
    "*What 3 data sources have you identified for this project?*\n",
    "*How are you going to relate these datasets?*\n",
    "üìù <!-- Answer Below -->\n",
    "1.Annual reports with comprehensive breach statistics are available as files or PDFs from the Identity Theft Resource Center (ITRC).\n",
    "2.Chronology of Data Breaches by Privacy Rights Clearinghouse is a searchable database that includes variables like date, organization type, and type of data exposed (database/CSV).\n",
    "3.The Breach Portal of the U.S. Department of Health and Human Services (HHS) contains comprehensive records of data breaches pertaining to healthcare (API and downloadable data).\n",
    "\n",
    "## 1. Exploratory Data Analysis (EDA)\n",
    "The goal of this section is to explore the structure and content of the merged breach datasets, summarize key statistics, and identify data issues or correlations.\n",
    "python\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "itrc_df = pd.read_csv(\"itrc_data.csv\")\n",
    "prc_df = pd.read_csv(\"privacy_rights.csv\")\n",
    "hhs_df = pd.read_csv(\"hhs_breaches.csv\")\n",
    "\n",
    "df = pd.concat([itrc_df, prc_df, hhs_df], ignore_index=True)\n",
    "\n",
    "df.head()\n",
    "python\n",
    "\n",
    "df.info()\n",
    "python\n",
    "\n",
    "df.describe()\n",
    "python\n",
    "\n",
    "print(\"Missing values:\\n\", df.isnull().sum())\n",
    "print(\"\\nDuplicate rows:\", df.duplicated().sum())\n",
    "python\n",
    "\n",
    "df.corr(numeric_only=True)\n",
    "\n",
    "\n",
    "### EDA Summary\n",
    "- The merged dataset contains [X rows] and [Y columns], covering data breaches from multiple sources.  \n",
    "- Common variables include Date, Organization Type, Records Exposed, Breach Type, and Location.  \n",
    "- Some datasets have missing values in Records Exposed and Breach Type.  \n",
    "- Outliers are present in the Records Exposed column, representing large-scale breaches (millions of records).  \n",
    "- Correlations show strong relationships between Year and Total Breaches* but weaker relationships between categorical variables.\n",
    "\n",
    "## Loading and Merging the Datasets \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "itrc_df = pd.read_csv(\"itrc_data.csv\")\n",
    "prc_df = pd.read_csv(\"privacy_rights.csv\")\n",
    "hhs_df = pd.read_csv(\"hhs_breaches.csv\")\n",
    "\n",
    "df = pd.concat([itrc_df, prc_df, hhs_df], ignore_index=True)\n",
    "df.head() \n",
    "\n",
    "## Data Overview \n",
    "df.info()\n",
    "df.describe()\n",
    "print(\"Missing values:\\n\", df.isnull().sum())\n",
    "print(\"\\nDuplicate rows:\", df.duplicated().sum())\n",
    "df.corr(numeric_only=True) \n",
    "\n",
    "## 2. Data Visualizations\n",
    "Below are four visualizations that reveal patterns and insights within the data breach datasets.\n",
    "\n",
    "\n",
    "# 1. Histogram - Breaches per Year\n",
    "sns.histplot(df['Year'], bins=20, kde=False, color='steelblue')\n",
    "plt.title('Distribution of Data Breaches Over Time')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Number of Breaches')\n",
    "plt.show()\n",
    "\n",
    "Insight:\n",
    "Breaches steadily rise from 2005‚Äì2023, showing either increased reporting or increased cyber activity.\n",
    "\n",
    "# 2. Scatter Plot - Records Exposed vs. Year\n",
    "plt.scatter(df['Year'], df['Records_Exposed'], alpha=0.5)\n",
    "plt.title('Records Exposed by Year')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Records Exposed (Millions)')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "Insight: \n",
    "Most breaches affect smaller numbers, but a few extreme events (e.g., Equifax) dominate exposure totals.\n",
    "\n",
    "\n",
    "# 3. Correlation Heatmap - Numeric features\n",
    "\n",
    "corr = df.corr(numeric_only=True)\n",
    "sns.heatmap(corr, annot=True, cmap='coolwarm', linewidths=0.5)\n",
    "plt.title('Correlation Heatmap - Breach Statistics')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "Insight:\n",
    "Years with more breaches tend to have higher total exposure totals.\n",
    "\n",
    "# 4. Boxplot - Outliers in Records Exposed\n",
    "sns.boxplot(x=df['Records_Exposed'])\n",
    "plt.title('Boxplot of Records Exposed')\n",
    "plt.xlabel('Records Exposed')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "Insight: \n",
    "Numerous severe outliers indicate very large breach events skewing the distribution.\n",
    "\n",
    "\n",
    "\n",
    "## 3. Data Cleaning and Transformations\n",
    "\n",
    "Cleaning steps performed based on EDA findings:\n",
    "- Filled missing numeric values with median values.\n",
    "- Removed duplicate rows across merged datasets.\n",
    "- Filtered extreme outliers above a certain threshold.\n",
    "- Converted *Year* to integer and *Date* to datetime type.\n",
    "\n",
    "df['Records_Exposed'] = df['Records_Exposed'].fillna(df['Records_Exposed'].median())\n",
    "df = df.drop_duplicates()\n",
    "df['Year'] = df['Year'].astype(int)\n",
    "df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "\n",
    "df = df[df['Records_Exposed'] < df['Records_Exposed'].quantile(0.99)]\n",
    "\n",
    "### Cleaning Summary\n",
    "\n",
    "Filled missing values using median imputation\n",
    "Removed duplicate rows\n",
    "Converted Date/Year formats\n",
    "Removed extreme outliers for cleaner modeling\n",
    "\n",
    "## 4. Machine Learning Plan\n",
    "Regression Models\n",
    "- To predict numerical severity:\n",
    "- Linear Regression\n",
    "- Random Forest Regressor\n",
    "- Gradient Boosting Regressor\n",
    "\n",
    "## Classification Models\n",
    "To categorize breaches into severity groups (Low/Medium/High):\n",
    "- Logistic Regression\n",
    "- Random Forest Classifier\n",
    "- Gradient Boosting Classifier\n",
    "- AdaBoost Classifier\n",
    "\n",
    "## Challenges Identified\n",
    "Challenge\t\n",
    "- Missing values\n",
    "- Outliers\t\n",
    "- Imbalanced severity classes\t\n",
    "- Mixed variable types\t\n",
    "\n",
    "Explanation\n",
    "- Not all reports include exposure numbers\n",
    "- Mega-breaches distort model accuracy\n",
    "- Few high-severity breaches\n",
    "- Need separate processing for categorical + numerical\n",
    "\n",
    "## Plan to Address These Challenges\n",
    "Challenge\t\n",
    "- Missing values\n",
    "- Outliers\n",
    "- Imbalanced data\t\n",
    "- Mixed types\t\n",
    "\n",
    "Solution\n",
    "- Use SimpleImputer in pipeline.\n",
    "- Use RobustScaler, remove top 1%. \n",
    "- Try class weights or SMOTE.\n",
    "- Use ColumnTransformer for separate processing.\n",
    "\n",
    "## Process (Pipelines, Scaling, Encoding)\n",
    "Can we predict breach severity or understand what factors most influence the number of records exposed?\n",
    "Example pipeline setup:\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "numeric_features = ['Year', 'Records_Exposed']\n",
    "categorical_features = ['Industry', 'Breach_Type']\n",
    "\n",
    "numeric_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_pipeline = Pipeline([\n",
    "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', numeric_pipeline, numeric_features),\n",
    "    ('cat', categorical_pipeline, categorical_features)\n",
    "])\n",
    "\n",
    "## Analyze ‚Äì Testing Multiple Models\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = Pipeline([\n",
    "    ('preprocess', preprocessor),\n",
    "    ('clf', RandomForestClassifier())\n",
    "])\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach and Analysis\n",
    "*What is your approach to answering your project question?*\n",
    "*How will you use the identified data to answer your project question?*\n",
    "üìù <!-- Start Discussing the project here; you can add as many code cells as you need -->\n",
    "\n",
    "\n",
    "breaches_by_industry = df['Industry'].value_counts().head(10)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "breaches_by_industry.plot(kind='bar')\n",
    "plt.title(\"Top 10 Industries by Data Breaches\")\n",
    "plt.xlabel(\"Industry\")\n",
    "plt.ylabel(\"Number of Breaches\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start your code here\n",
    "# Compare breaches by industry\n",
    "breaches_by_industry = df['Industry'].value_counts().head(10)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "breaches_by_industry.plot(kind='bar')\n",
    "plt.title(\"Top 10 Industries by Data Breaches\")\n",
    "plt.xlabel(\"Industry\")\n",
    "plt.ylabel(\"Number of Breaches\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources and References\n",
    "*What resources and references have you used for this project?*\n",
    "üìù <!-- Answer Below -->\n",
    "https://www.nist.gov/cyberframework\n",
    "https://ocrportal.hhs.gov/ocr/breach/breach_report.jsf\n",
    "https://privacyrights.org/\n",
    "https://www.idtheftcenter.org/\n",
    "https://www.cisa.gov/\n",
    "https://pandas.pydata.org/docs/\n",
    "https://ocrportal.hhs.gov/ocr/breach/breach_report.jsf\n",
    "https://privacyrights.org/data-breaches\n",
    "https://www.idtheftcenter.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook source.ipynb to python\n",
      "[NbConvertApp] Writing 1271 bytes to source.py\n"
     ]
    }
   ],
   "source": [
    "# ‚ö†Ô∏è Make sure you run this cell at the end of your notebook before every submission!\n",
    "!jupyter nbconvert --to python source.ipynb\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Final-Project-Template-unx06iZ2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8f59090b806211711d8ea6da25ee5b1ccb272a75a21b9536283520350d8dfda7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
