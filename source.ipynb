{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# {The Rising Impact of Data Breaches in the U.S.}üìù\n",
    "\n",
    "![Banner](./assets/banner.jpeg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic\n",
    "*What problem are you (or your stakeholder) trying to address?*\n",
    "üìù <!-- Answer Below -->\n",
    "I want to talk about cybersecurity and data privacy, specifically analyzing patterns in data \n",
    "breaches in the United States. Every year, millions of people are affected by compromised personal \n",
    "data, which can result in identity theft, financial loss, and a decline in faith in businesses and \n",
    "technology. The rise of cloud platforms, artificial intelligence, and digitalservices has led to a \n",
    "rise in the collection of sensitive data, but laws and safeguards are frequently lagging behind. \n",
    "This makes the topic important today. Analyzing breach trends can help us identify weak points and \n",
    "improve data security for both individuals and corporations."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Question\n",
    "*What specific question are you seeking to answer with this project?*\n",
    "*This is not the same as the questions you ask to limit the scope of the project.*\n",
    "üìù <!-- Answer Below -->\n",
    "1. How have data breaches in the US changed over time in terms of both quantity and severity?\n",
    "2. Which sectors are most commonly the focus of data breaches caused by cyberattacks?\n",
    "3. What types of data (financial, healthcare, personal identifiers, etc.) are most often compromised, and what patterns exist?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What would an answer look like?\n",
    "*What is your hypothesized answer to your question?*\n",
    "üìù <!-- Answer Below -->\n",
    "A line chart showing the number of breaches per year.\n",
    "A bar chart comparing breaches across industries.\n",
    "A stacked bar or pie chart showing the breakdown of data types exposed."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Sources\n",
    "*What 3 data sources have you identified for this project?*\n",
    "*How are you going to relate these datasets?*\n",
    "üìù <!-- Answer Below -->\n",
    "1.Annual reports with comprehensive breach statistics are available as files or PDFs from the Identity Theft Resource Center (ITRC).\n",
    "2.Chronology of Data Breaches by Privacy Rights Clearinghouse is a searchable database that includes variables like date, organization type, and type of data exposed (database/CSV).\n",
    "3.The Breach Portal of the U.S. Department of Health and Human Services (HHS) contains comprehensive records of data breaches pertaining to healthcare (API and downloadable data).\n",
    "\n",
    "## 1. Exploratory Data Analysis (EDA)\n",
    "The goal of this section is to explore the structure and content of the merged breach datasets, summarize key statistics, and identify data issues or correlations.\n",
    "python\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "itrc_df = pd.read_csv(\"itrc_data.csv\")\n",
    "prc_df = pd.read_csv(\"privacy_rights.csv\")\n",
    "hhs_df = pd.read_csv(\"hhs_breaches.csv\")\n",
    "\n",
    "df = pd.concat([itrc_df, prc_df, hhs_df], ignore_index=True)\n",
    "\n",
    "df.head()\n",
    "python\n",
    "\n",
    "df.info()\n",
    "python\n",
    "\n",
    "df.describe()\n",
    "python\n",
    "\n",
    "print(\"Missing values:\\n\", df.isnull().sum())\n",
    "print(\"\\nDuplicate rows:\", df.duplicated().sum())\n",
    "python\n",
    "\n",
    "df.corr(numeric_only=True)\n",
    "markdown\n",
    "\n",
    "### EDA Summary\n",
    "- The merged dataset contains [X rows] and [Y columns], covering data breaches from multiple sources.  \n",
    "- Common variables include Date, Organization Type, Records Exposed, Breach Type, and Location.  \n",
    "- Some datasets have missing values in Records Exposed and Breach Type.  \n",
    "- Outliers are present in the Records Exposed column, representing large-scale breaches (millions of records).  \n",
    "- Correlations show strong relationships between Year and Total Breaches* but weaker relationships between categorical variables.\n",
    "\n",
    "## 2. Data Visualizations\n",
    "Below are four visualizations that reveal patterns and insights within the data breach datasets.\n",
    "python\n",
    "\n",
    "# 1. Histogram - Number of breaches per year\n",
    "sns.histplot(df['Year'], bins=20, kde=False, color='steelblue')\n",
    "plt.title('Distribution of Data Breaches Over Time')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Number of Breaches')\n",
    "plt.show()\n",
    "markdown\n",
    "\n",
    "Insight:\n",
    "This histogram shows a steady increase in reported breaches from 2005 to 2023. The trend suggests that either data collection has improved or cyber incidents have become more frequent.\n",
    "python\n",
    "\n",
    "# 2. Scatter Plot - Records Exposed vs. Year\n",
    "plt.scatter(df['Year'], df['Records_Exposed'], alpha=0.5)\n",
    "plt.title('Records Exposed by Year')\n",
    "plt.xlabel('Year')\n",
    "plt.ylabel('Records Exposed (in millions)')\n",
    "plt.show()\n",
    "markdown\n",
    "\n",
    "Insight: \n",
    "The scatter plot indicates that while most breaches affect under 1 million records, a few large-scale events (e.g., 2017 Equifax breach) significantly skew the distribution. These outliers represent critical anomalies.\n",
    "python\n",
    "\n",
    "# 3. Correlation Heatmap - Numeric features\n",
    "corr = df.corr(numeric_only=True)\n",
    "sns.heatmap(corr, annot=True, cmap='coolwarm', linewidths=0.5)\n",
    "plt.title('Correlation Heatmap - Breach Statistics')\n",
    "plt.show()\n",
    "markdown\n",
    "\n",
    "Insight:\n",
    "This heatmap reveals moderate positive correlation between *Number of Breaches* and *Records Exposed*, suggesting that years with more breaches often have higher total exposure counts.\n",
    "python\n",
    "\n",
    "# 4. Boxplot - Outliers in Records Exposed\n",
    "sns.boxplot(x=df['Records_Exposed'])\n",
    "plt.title('Boxplot of Records Exposed')\n",
    "plt.xlabel('Records Exposed')\n",
    "plt.show()\n",
    "markdown\n",
    "\n",
    "Insight: \n",
    "The boxplot highlights several extreme outliers in the *Records Exposed* column. These represent large-scale breaches that distort averages but are important for risk analysis.\n",
    "markdown\n",
    "\n",
    "\n",
    "## 3. Data Cleaning and Transformations\n",
    "\n",
    "Cleaning steps performed based on EDA findings:\n",
    "- Filled missing numeric values with median values.\n",
    "- Removed duplicate rows across merged datasets.\n",
    "- Filtered extreme outliers above a certain threshold.\n",
    "- Converted *Year* to integer and *Date* to datetime type.\n",
    "\n",
    "df['Records_Exposed'] = df['Records_Exposed'].fillna(df['Records_Exposed'].median())\n",
    "\n",
    "df = df.drop_duplicates()\n",
    "\n",
    "df['Year'] = df['Year'].astype(int)\n",
    "\n",
    "df['Date'] = pd.to_datetime(df['Date'], errors='coerce')\n",
    "\n",
    "df = df[df['Records_Exposed'] < df['Records_Exposed'].quantile(0.99)]\n",
    "markdown\n",
    "\n",
    "### Cleaning Summary\n",
    "After cleaning:\n",
    "- Missing *Records_Exposed* values were replaced with the median.  \n",
    "- Duplicates removed across sources.  \n",
    "- Converted *Year* and *Date* fields to appropriate data types.  \n",
    "- Removed the top 1% of outliers to improve statistical reliability.  \n",
    "The dataset is now consistent and ready for further analysis.\n",
    "\n",
    "## 4. Machine Learning Plan\n",
    "\n",
    "Based on the current dataset and features, the goal is to predict the number of records exposed or classify breach severity using machine learning.\n",
    "\n",
    "- ML Type: Regression and Classification  \n",
    "- Goal: Predict the severity of a breach based on type, organization, and year.  \n",
    "- Potential Models: Linear Regression, Random Forest, or Logistic Regression.  \n",
    "- Challenges:\n",
    "  - Data imbalance (few high-severity breaches)\n",
    "  - Missing categorical data (some sectors underrepresented)\n",
    "  - Outliers skewing model training\n",
    "\n",
    "Example Plan\n",
    "> I plan to start with a regression model to predict *Records Exposed*.  \n",
    "> Features such as *Breach Type*, *Industry*, and *Year* will serve as predictors.  \n",
    "> I may later use a classification model to categorize breaches into ‚ÄúLow,‚Äù ‚ÄúMedium,‚Äù or ‚ÄúHigh‚Äù severity groups.  \n",
    "> Main challenges include handling unbalanced data and minimizing overfitting due to a few very large breaches.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach and Analysis\n",
    "*What is your approach to answering your project question?*\n",
    "*How will you use the identified data to answer your project question?*\n",
    "üìù <!-- Start Discussing the project here; you can add as many code cells as you need -->\n",
    "sns.histplot(df['Sales'], kde=True)\n",
    "plt.title('Distribution of Global Sales')\n",
    "plt.show()\n",
    "\n",
    "sns.heatmap(df.corr(numeric_only=True), annot=True, cmap='coolwarm')\n",
    "\n",
    "df.isnull().sum()\n",
    "df.duplicated().sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start your code here\n",
    "# Compare breaches by industry\n",
    "breaches_by_industry = df['Industry'].value_counts().head(10)\n",
    "\n",
    "plt.figure(figsize=(10,6))\n",
    "breaches_by_industry.plot(kind='bar')\n",
    "plt.title(\"Top 10 Industries by Data Breaches\")\n",
    "plt.xlabel(\"Industry\")\n",
    "plt.ylabel(\"Number of Breaches\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resources and References\n",
    "*What resources and references have you used for this project?*\n",
    "üìù <!-- Answer Below -->\n",
    "https://www.nist.gov/cyberframework\n",
    "https://ocrportal.hhs.gov/ocr/breach/breach_report.jsf\n",
    "https://privacyrights.org/\n",
    "https://www.idtheftcenter.org/\n",
    "https://www.cisa.gov/\n",
    "https://pandas.pydata.org/docs/\n",
    "https://ocrportal.hhs.gov/ocr/breach/breach_report.jsf\n",
    "https://privacyrights.org/data-breaches\n",
    "https://www.idtheftcenter.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook source.ipynb to python\n",
      "[NbConvertApp] Writing 1271 bytes to source.py\n"
     ]
    }
   ],
   "source": [
    "# ‚ö†Ô∏è Make sure you run this cell at the end of your notebook before every submission!\n",
    "!jupyter nbconvert --to python source.ipynb\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Final-Project-Template-unx06iZ2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8f59090b806211711d8ea6da25ee5b1ccb272a75a21b9536283520350d8dfda7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
